{
  "nodes": [
    {
      "width": 300,
      "height": 480,
      "id": "conversationalRetrievalQAChain_0",
      "position": {
        "x": 1403.7835870967742,
        "y": 147.02417548387095
      },
      "type": "customNode",
      "data": {
        "id": "conversationalRetrievalQAChain_0",
        "label": "Conversational Retrieval QA Chain",
        "version": 1,
        "name": "conversationalRetrievalQAChain",
        "type": "ConversationalRetrievalQAChain",
        "baseClasses": [
          "ConversationalRetrievalQAChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
        "inputParams": [
          {
            "label": "Return Source Documents",
            "name": "returnSourceDocuments",
            "type": "boolean",
            "optional": true,
            "id": "conversationalRetrievalQAChain_0-input-returnSourceDocuments-boolean"
          },
          {
            "label": "System Message",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "placeholder": "I want you to act as a document that I am having a conversation with. Your name is \"AI Assistant\". You will provide me with answers from the given info. If the answer is not included, say exactly \"Hmm, I am not sure.\" and stop after that. Refuse to answer any question not about the info. Never break character.",
            "id": "conversationalRetrievalQAChain_0-input-systemMessagePrompt-string"
          },
          {
            "label": "Chain Option",
            "name": "chainOption",
            "type": "options",
            "options": [
              {
                "label": "MapReduceDocumentsChain",
                "name": "map_reduce",
                "description": "Suitable for QA tasks over larger documents and can run the preprocessing step in parallel, reducing the running time"
              },
              {
                "label": "RefineDocumentsChain",
                "name": "refine",
                "description": "Suitable for QA tasks over a large number of documents."
              },
              {
                "label": "StuffDocumentsChain",
                "name": "stuff",
                "description": "Suitable for QA tasks over a small number of documents."
              }
            ],
            "additionalParams": true,
            "optional": true,
            "id": "conversationalRetrievalQAChain_0-input-chainOption-options"
          }
        ],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "conversationalRetrievalQAChain_0-input-model-BaseLanguageModel"
          },
          {
            "label": "Vector Store Retriever",
            "name": "vectorStoreRetriever",
            "type": "BaseRetriever",
            "id": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseMemory",
            "optional": true,
            "description": "If left empty, a default BufferMemory will be used",
            "id": "conversationalRetrievalQAChain_0-input-memory-BaseMemory"
          }
        ],
        "inputs": {
          "model": "{{chatHuggingFace_0.data.instance}}",
          "vectorStoreRetriever": "{{memoryVectorStore_0.data.instance}}",
          "memory": "{{bufferMemory_0.data.instance}}",
          "returnSourceDocuments": true,
          "systemMessagePrompt": "",
          "chainOption": ""
        },
        "outputAnchors": [
          {
            "id": "conversationalRetrievalQAChain_0-output-conversationalRetrievalQAChain-ConversationalRetrievalQAChain|BaseChain|Runnable",
            "name": "conversationalRetrievalQAChain",
            "label": "ConversationalRetrievalQAChain",
            "type": "ConversationalRetrievalQAChain | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "selected": false,
      "positionAbsolute": {
        "x": 1403.7835870967742,
        "y": 147.02417548387095
      },
      "dragging": false
    },
    {
      "width": 300,
      "height": 577,
      "id": "chatHuggingFace_0",
      "position": {
        "x": 872.3120412903229,
        "y": -228.40444903225807
      },
      "type": "customNode",
      "data": {
        "id": "chatHuggingFace_0",
        "label": "ChatHuggingFace",
        "version": 2,
        "name": "chatHuggingFace",
        "type": "ChatHuggingFace",
        "baseClasses": [
          "ChatHuggingFace",
          "BaseChatModel",
          "LLM",
          "BaseLLM",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around HuggingFace large language models",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "huggingFaceApi"
            ],
            "id": "chatHuggingFace_0-input-credential-credential"
          },
          {
            "label": "Model",
            "name": "model",
            "type": "string",
            "description": "If using own inference endpoint, leave this blank",
            "placeholder": "gpt2",
            "optional": true,
            "id": "chatHuggingFace_0-input-model-string"
          },
          {
            "label": "Endpoint",
            "name": "endpoint",
            "type": "string",
            "placeholder": "https://xyz.eu-west-1.aws.endpoints.huggingface.cloud/gpt2",
            "description": "Using your own inference endpoint",
            "optional": true,
            "id": "chatHuggingFace_0-input-endpoint-string"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "description": "Temperature parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "chatHuggingFace_0-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "description": "Max Tokens parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "chatHuggingFace_0-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "description": "Top Probability parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "chatHuggingFace_0-input-topP-number"
          },
          {
            "label": "Top K",
            "name": "hfTopK",
            "type": "number",
            "step": 0.1,
            "description": "Top K parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "chatHuggingFace_0-input-hfTopK-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "description": "Frequency Penalty parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "chatHuggingFace_0-input-frequencyPenalty-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatHuggingFace_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "model": "tiiuae/falcon-7b-instruct",
          "endpoint": "",
          "temperature": "",
          "maxTokens": "",
          "topP": "",
          "hfTopK": "",
          "frequencyPenalty": ""
        },
        "outputAnchors": [
          {
            "id": "chatHuggingFace_0-output-chatHuggingFace-ChatHuggingFace|BaseChatModel|LLM|BaseLLM|BaseLanguageModel|Runnable",
            "name": "chatHuggingFace",
            "label": "ChatHuggingFace",
            "type": "ChatHuggingFace | BaseChatModel | LLM | BaseLLM | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "selected": false,
      "positionAbsolute": {
        "x": 872.3120412903229,
        "y": -228.40444903225807
      },
      "dragging": false
    },
    {
      "width": 300,
      "height": 376,
      "id": "bufferMemory_0",
      "position": {
        "x": 1019.8141212903226,
        "y": 407.7135999999998
      },
      "type": "customNode",
      "data": {
        "id": "bufferMemory_0",
        "label": "Buffer Memory",
        "version": 1,
        "name": "bufferMemory",
        "type": "BufferMemory",
        "baseClasses": [
          "BufferMemory",
          "BaseChatMemory",
          "BaseMemory"
        ],
        "category": "Memory",
        "description": "Remembers previous conversational back and forths directly",
        "inputParams": [
          {
            "label": "Memory Key",
            "name": "memoryKey",
            "type": "string",
            "default": "chat_history",
            "id": "bufferMemory_0-input-memoryKey-string"
          },
          {
            "label": "Input Key",
            "name": "inputKey",
            "type": "string",
            "default": "input",
            "id": "bufferMemory_0-input-inputKey-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "memoryKey": "chat_history",
          "inputKey": "input"
        },
        "outputAnchors": [
          {
            "id": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
            "name": "bufferMemory",
            "label": "BufferMemory",
            "type": "BufferMemory | BaseChatMemory | BaseMemory"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "selected": false,
      "positionAbsolute": {
        "x": 1019.8141212903226,
        "y": 407.7135999999998
      },
      "dragging": false
    },
    {
      "width": 300,
      "height": 475,
      "id": "huggingFaceInferenceEmbeddings_0",
      "position": {
        "x": 159.81862193548415,
        "y": 332.6980968709677
      },
      "type": "customNode",
      "data": {
        "id": "huggingFaceInferenceEmbeddings_0",
        "label": "HuggingFace Inference Embeddings",
        "version": 1,
        "name": "huggingFaceInferenceEmbeddings",
        "type": "HuggingFaceInferenceEmbeddings",
        "baseClasses": [
          "HuggingFaceInferenceEmbeddings",
          "Embeddings"
        ],
        "category": "Embeddings",
        "description": "HuggingFace Inference API to generate embeddings for a given text",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "huggingFaceApi"
            ],
            "id": "huggingFaceInferenceEmbeddings_0-input-credential-credential"
          },
          {
            "label": "Model",
            "name": "modelName",
            "type": "string",
            "description": "If using own inference endpoint, leave this blank",
            "placeholder": "sentence-transformers/distilbert-base-nli-mean-tokens",
            "optional": true,
            "id": "huggingFaceInferenceEmbeddings_0-input-modelName-string"
          },
          {
            "label": "Endpoint",
            "name": "endpoint",
            "type": "string",
            "placeholder": "https://xyz.eu-west-1.aws.endpoints.huggingface.cloud/sentence-transformers/all-MiniLM-L6-v2",
            "description": "Using your own inference endpoint",
            "optional": true,
            "id": "huggingFaceInferenceEmbeddings_0-input-endpoint-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "modelName": "BAAI/bge-small-en-v1.5",
          "endpoint": ""
        },
        "outputAnchors": [
          {
            "id": "huggingFaceInferenceEmbeddings_0-output-huggingFaceInferenceEmbeddings-HuggingFaceInferenceEmbeddings|Embeddings",
            "name": "huggingFaceInferenceEmbeddings",
            "label": "HuggingFaceInferenceEmbeddings",
            "type": "HuggingFaceInferenceEmbeddings | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "selected": false,
      "positionAbsolute": {
        "x": 159.81862193548415,
        "y": 332.6980968709677
      },
      "dragging": false
    },
    {
      "width": 300,
      "height": 406,
      "id": "memoryVectorStore_0",
      "position": {
        "x": 527.1267612903227,
        "y": 210.85068525806452
      },
      "type": "customNode",
      "data": {
        "id": "memoryVectorStore_0",
        "label": "In-Memory Vector Store",
        "version": 1,
        "name": "memoryVectorStore",
        "type": "Memory",
        "baseClasses": [
          "Memory",
          "VectorStoreRetriever",
          "BaseRetriever"
        ],
        "category": "Vector Stores",
        "description": "In-memory vectorstore that stores embeddings and does an exact, linear search for the most similar embeddings.",
        "inputParams": [
          {
            "label": "Top K",
            "name": "topK",
            "description": "Number of top results to fetch. Default to 4",
            "placeholder": "4",
            "type": "number",
            "optional": true,
            "id": "memoryVectorStore_0-input-topK-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "list": true,
            "optional": true,
            "id": "memoryVectorStore_0-input-document-Document"
          },
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "memoryVectorStore_0-input-embeddings-Embeddings"
          }
        ],
        "inputs": {
          "document": [
            "{{pdfFile_0.data.instance}}"
          ],
          "embeddings": "{{huggingFaceInferenceEmbeddings_0.data.instance}}",
          "topK": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "options": [
              {
                "id": "memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever",
                "name": "retriever",
                "label": "Memory Retriever",
                "type": "Memory | VectorStoreRetriever | BaseRetriever"
              },
              {
                "id": "memoryVectorStore_0-output-vectorStore-Memory|VectorStore",
                "name": "vectorStore",
                "label": "Memory Vector Store",
                "type": "Memory | VectorStore"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "retriever"
        },
        "selected": false
      },
      "selected": false,
      "positionAbsolute": {
        "x": 527.1267612903227,
        "y": 210.85068525806452
      },
      "dragging": false
    },
    {
      "width": 300,
      "height": 507,
      "id": "pdfFile_0",
      "position": {
        "x": 156.28681290322615,
        "y": -220.38319758064503
      },
      "type": "customNode",
      "data": {
        "id": "pdfFile_0",
        "label": "Pdf File",
        "version": 1,
        "name": "pdfFile",
        "type": "Document",
        "baseClasses": [
          "Document"
        ],
        "category": "Document Loaders",
        "description": "Load data from PDF files",
        "inputParams": [
          {
            "label": "Pdf File",
            "name": "pdfFile",
            "type": "file",
            "fileType": ".pdf",
            "id": "pdfFile_0-input-pdfFile-file"
          },
          {
            "label": "Usage",
            "name": "usage",
            "type": "options",
            "options": [
              {
                "label": "One document per page",
                "name": "perPage"
              },
              {
                "label": "One document per file",
                "name": "perFile"
              }
            ],
            "default": "perPage",
            "id": "pdfFile_0-input-usage-options"
          },
          {
            "label": "Use Legacy Build",
            "name": "legacyBuild",
            "type": "boolean",
            "optional": true,
            "additionalParams": true,
            "id": "pdfFile_0-input-legacyBuild-boolean"
          },
          {
            "label": "Metadata",
            "name": "metadata",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "pdfFile_0-input-metadata-json"
          }
        ],
        "inputAnchors": [
          {
            "label": "Text Splitter",
            "name": "textSplitter",
            "type": "TextSplitter",
            "optional": true,
            "id": "pdfFile_0-input-textSplitter-TextSplitter"
          }
        ],
        "inputs": {
          "textSplitter": "",
          "usage": "perPage",
          "legacyBuild": "",
          "metadata": ""
        },
        "outputAnchors": [
          {
            "id": "pdfFile_0-output-pdfFile-Document",
            "name": "pdfFile",
            "label": "Document",
            "type": "Document"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "selected": false,
      "positionAbsolute": {
        "x": 156.28681290322615,
        "y": -220.38319758064503
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "chatHuggingFace_0",
      "sourceHandle": "chatHuggingFace_0-output-chatHuggingFace-ChatHuggingFace|BaseChatModel|LLM|BaseLLM|BaseLanguageModel|Runnable",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-model-BaseLanguageModel",
      "type": "buttonedge",
      "id": "chatHuggingFace_0-chatHuggingFace_0-output-chatHuggingFace-ChatHuggingFace|BaseChatModel|LLM|BaseLLM|BaseLanguageModel|Runnable-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-model-BaseLanguageModel"
    },
    {
      "source": "bufferMemory_0",
      "sourceHandle": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-memory-BaseMemory",
      "type": "buttonedge",
      "id": "bufferMemory_0-bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-memory-BaseMemory"
    },
    {
      "source": "huggingFaceInferenceEmbeddings_0",
      "sourceHandle": "huggingFaceInferenceEmbeddings_0-output-huggingFaceInferenceEmbeddings-HuggingFaceInferenceEmbeddings|Embeddings",
      "target": "memoryVectorStore_0",
      "targetHandle": "memoryVectorStore_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "huggingFaceInferenceEmbeddings_0-huggingFaceInferenceEmbeddings_0-output-huggingFaceInferenceEmbeddings-HuggingFaceInferenceEmbeddings|Embeddings-memoryVectorStore_0-memoryVectorStore_0-input-embeddings-Embeddings"
    },
    {
      "source": "memoryVectorStore_0",
      "sourceHandle": "memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
      "type": "buttonedge",
      "id": "memoryVectorStore_0-memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
    },
    {
      "source": "pdfFile_0",
      "sourceHandle": "pdfFile_0-output-pdfFile-Document",
      "target": "memoryVectorStore_0",
      "targetHandle": "memoryVectorStore_0-input-document-Document",
      "type": "buttonedge",
      "id": "pdfFile_0-pdfFile_0-output-pdfFile-Document-memoryVectorStore_0-memoryVectorStore_0-input-document-Document"
    }
  ]
}